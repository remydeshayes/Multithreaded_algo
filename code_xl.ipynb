{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import random\n",
    "from sklearn.linear_model import Lasso, lasso_path\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib.cm as cm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "memo_time = []\n",
    "import timeit\n",
    "\n",
    "def unit(x):\n",
    "    if x >= 1: return \"%1.2f s\" % x\n",
    "    elif x >= 1e-3: return \"%1.2f ms\" % (x* 1000)\n",
    "    elif x >= 1e-6: return \"%1.2f µs\" % (x* 1000**2)\n",
    "    elif x >= 1e-9: return \"%1.2f ns\" % (x* 1000**3)\n",
    "    else:\n",
    "        return \"%1.2g s\" % x\n",
    "\n",
    "def timeexe(legend, code, number=10, repeat=10):\n",
    "    rep = timeit.repeat(code, number=number, repeat=repeat, globals=globals())\n",
    "    ave = sum(rep) / (number * repeat)\n",
    "    std = (sum((x/number - ave)**2 for x in rep) / repeat)**0.5\n",
    "    fir = rep[0]/number\n",
    "    fir3 = sum(rep[:3]) / (3 * number)\n",
    "    las3 = sum(rep[-3:]) / (3 * number)\n",
    "    rep.sort()\n",
    "    mini = rep[len(rep)//20] / number\n",
    "    maxi = rep[-len(rep)//20] / number\n",
    "    print(\"Moyenne: %s Ecart-type %s (with %d runs) in [%s, %s]\" % (\n",
    "                unit(ave), unit(std), number, unit(mini), unit(maxi)))\n",
    "    return dict(legend=legend, average=ave, deviation=std, first=fir, first3=fir3,\n",
    "                last3=las3, repeat=repeat, min5=mini, max5=maxi, code=code, run=number)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2 id=\"0/-Import-data\"> Import data<a class=\"anchor-link\" href=\"#0/-Import-data\">¶</a></h2><p>Motivation Paper: <a href=\"https://arxiv.org/pdf/1411.6520v1.pdf\">https://arxiv.org/pdf/1411.6520v1.pdf</a></p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filename = \"path\"\n",
    "key = \"clean_data\"\n",
    "Data = pd.read_hdf(filename,key)\n",
    "Data = Data.select_dtypes(include='number')\n",
    "Data.head(3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(Data.shape)\n",
    "print()\n",
    "print(Data.dtypes)\n",
    "print()\n",
    "print(Data.columns)\n",
    "print()\n",
    "print(Data.isnull().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = Data.drop('likes', axis=1)\n",
    "y = Data['likes']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2 id=\"1/-Baseline-model\">Baseline model<a class=\"anchor-link\" href=\"#1/-Baseline-model\">¶</a></h2><ul>\n",
    "<li><a href=\"https://www.geeksforgeeks.org/implementation-of-lasso-regression-from-scratch-using-python/\">Lasso from scratch</a></li>\n",
    "<li><a href=\"https://stats.stackexchange.com/questions/123672/coordinate-descent-soft-thresholding-update-operator-for-lasso\">Lasso theory </a></li>\n",
    "<li><a href=\"https://xavierbourretsicotte.github.io/lasso_implementation.html\">Gradient descent for Lasso</a></li>\n",
    "<li><a href=\"https://github.com/satopirka/Lasso/blob/master/coordinate_descent_lasso.py\">Gradient descent code</a></li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def soft_threshold(rho, alpha):\n",
    "    if rho < -alpha:\n",
    "        return (rho + alpha)\n",
    "    elif rho >  alpha:\n",
    "        return (rho - alpha)\n",
    "    else: \n",
    "        return 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Baseline_Lasso(X, y, max_iter, alpha, intercept=False):\n",
    "    \n",
    "    n = X.shape[0]\n",
    "    \n",
    "    if intercept == True:\n",
    "        X_train.insert(0, \"intercept\", 1)\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    beta = np.zeros(m)\n",
    "    tmp_beta = np.zeros(m)\n",
    "    \n",
    "    for i in range(max_iter):\n",
    "        \n",
    "        start = 1 if intercept == True else 0\n",
    "        \n",
    "        for j in range(start, m):\n",
    "            loss_j = y - np.dot(X, tmp_beta)\n",
    "            rho = np.dot(X.iloc[:, j], loss_j)\n",
    "            beta[j] = soft_threshold(rho, alpha) / (X.iloc[:, j]**2).sum()\n",
    "\n",
    "    if intercept == True:\n",
    "        beta[0] = np.sum(y - np.dot(X.iloc[:, 1:], beta[1:])) / (X.shape[0])\n",
    "\n",
    "    return beta\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Baseline_Lasso(X, y, alpha=0.1, max_iter=500, intercept=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%timeit Baseline_Lasso(X, y, alpha=0.1, max_iter=500)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "memo_time.append(timeexe(\"Numpy\", \"Baseline_Lasso(X, y, alpha=0.1, max_iter=500)\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2 id=\"2/-Scikit-Learn-optimization\">Scikit-Learn optimization<a class=\"anchor-link\" href=\"#2/-Scikit-Learn-optimization\">¶</a></h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "regLasso = Lasso(fit_intercept=False, normalize=True)\n",
    "regLasso.fit(X, y)\n",
    "print(regLasso.coef_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%timeit regLasso.fit(X, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "memo_time.append(timeexe(\"SkLearn\", \"regLasso.fit(X, y)\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2 id=\"3/-Cython-optimization\"> Cython optimization<a class=\"anchor-link\" href=\"#3/-Cython-optimization\">¶</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%load_ext cython\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"3.1)-Version-homemade\">homemade<a class=\"anchor-link\" href=\"#3.1)-Version-homemade\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%%cython\n",
    "cimport cython\n",
    "cimport numpy as cnp\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "@cython.cdivision(True)\n",
    "cdef double soft_threshold_c1(double rho, double alpha) nogil:\n",
    "    if rho < -alpha:\n",
    "        return (rho + alpha)\n",
    "    elif rho > alpha:\n",
    "        return (rho - alpha)\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "@cython.cdivision(True)\n",
    "cdef double[:] loss_c(double[:] y, double[:] y_pred, double[:] loss) nogil:\n",
    "        \n",
    "    for i in range(0, len(y)):\n",
    "        loss[i] += y[i] - y_pred[i]\n",
    "        \n",
    "    return loss\n",
    "\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "@cython.cdivision(True)\n",
    "cdef double[:] y_pred_c(double[:, :] X, double[:] tmp_beta, double[:] y_pred, int j) nogil:\n",
    "    \n",
    "    cdef:\n",
    "        int n = X.shape[0]\n",
    "        int m = X.shape[1]\n",
    "        \n",
    "    for i in range(0, n):\n",
    "        y_pred[i] += X[i, j] * tmp_beta[j]\n",
    "            \n",
    "    return y_pred\n",
    "\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "@cython.cdivision(True)\n",
    "cdef double rho_c(double[:, :] X, double[:] y_pred, double rho, int j) nogil:\n",
    "    \n",
    "    cdef int n = X.shape[0]\n",
    "        \n",
    "    for i in range(0, n):\n",
    "        rho += X[i, j] * y_pred[i]\n",
    "        \n",
    "    return rho\n",
    "\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "@cython.cdivision(True)\n",
    "cdef double normalisation_c(double[:, :] X, double X_nrm, int j) nogil:\n",
    "    \n",
    "    cdef int n = X.shape[0]\n",
    "        \n",
    "    for i in range(0, n):\n",
    "        X_nrm += X[i, j]**2\n",
    "        \n",
    "    return X_nrm\n",
    "\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "@cython.cdivision(True)\n",
    "cdef double[:] fit1(double[:, :] X, double[:] y, int max_iter, float alpha,\n",
    "                   int n, int m, double[:] beta, double[:] tmp_beta,\n",
    "                   double[:] y_pred, double[:] loss, double X_nrm, double rho):\n",
    "    \n",
    "    cdef int i, j\n",
    "\n",
    "    for i in range(max_iter):\n",
    "\n",
    "        for j in range(m):\n",
    "            \n",
    "            y_pred_c(X, tmp_beta, y_pred, j)\n",
    "            loss_c(y, y_pred, loss)\n",
    "            rho_c(X, y_pred, rho, j)\n",
    "            beta[j] = soft_threshold_c1(rho, alpha) / normalisation_c(X, X_nrm, j) #(X.iloc[:, j]**2).sum()\n",
    "            \n",
    "    return beta\n",
    "\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "@cython.cdivision(True)\n",
    "def Cython_Lasso1(double[:, :] X, double[:] y, float alpha, int max_iter):\n",
    "\n",
    "    cdef: #initialisation\n",
    "        int n = X.shape[0]\n",
    "        int m = X.shape[1]\n",
    "        double[:] beta = np.zeros(m, dtype=np.float64)\n",
    "        double[:] tmp_beta = np.zeros(m, dtype=np.float64)\n",
    "        double[:] y_pred = np.empty(n, dtype=np.float64)\n",
    "        double[:] loss = np.empty(n, dtype=np.float64)\n",
    "        double X_nrm = 0.0\n",
    "        double rho = 0.0\n",
    "        \n",
    "        sol = fit1(X, y, max_iter, alpha, n, m, beta, tmp_beta, y_pred, loss, X_nrm, rho)\n",
    "\n",
    "    return np.asarray(sol)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_val = X.values.astype(np.float64)\n",
    "y_val = y.values.astype(np.float64)\n",
    "Cython_Lasso1(X_val, y_val, alpha=0.1, max_iter=500)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%timeit Cython_Lasso1(X_val, y_val, alpha=0.1, max_iter=500)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "memo_time.append(timeexe(\"Cython_homemade\", \"Cython_Lasso1(X_val, y_val, alpha=0.1, max_iter=500)\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"3.2)-Version-library-Blas\">Blas<a class=\"anchor-link\" href=\"#3.2)-Version-library-Blas\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%%cython\n",
    "cimport cython\n",
    "cimport numpy as np\n",
    "import numpy as np\n",
    "from libc.math cimport fabs, sqrt\n",
    "from scipy.linalg.cython_blas cimport ddot, dasum, daxpy, dnrm2, dcopy, dscal\n",
    "\n",
    "\n",
    "cdef double soft_threshold_c2(double f) nogil:\n",
    "    if f == 0:\n",
    "        return 0\n",
    "    elif f > 0:\n",
    "        return 1.0\n",
    "    else:\n",
    "        return -1.0\n",
    "\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "@cython.cdivision(True)\n",
    "cdef double[:] fit2(double[::1, :] X, double[:] norms_X_col, double[:] y,\n",
    "                   double[:] beta_tmp, double[:] beta, double alpha,\n",
    "                   int n, int m, int max_iter) nogil:\n",
    "\n",
    "    cdef:\n",
    "        int inc = 1\n",
    "        double tmp\n",
    "        double mbetaj\n",
    "\n",
    "    dcopy(&n, &y[0], &inc, &beta_tmp[0], &inc) #R[0] <- y[0]\n",
    "    for i in range(max_iter):\n",
    "\n",
    "        for j in range(m):\n",
    "\n",
    "            if beta[j] != 0.:\n",
    "                daxpy(&n, &beta[j], &X[0, j], &inc, &beta_tmp[0], &inc) #R += X[:, j] * beta[j]\n",
    "                \n",
    "            tmp = ddot(&n, &beta_tmp[0], &inc, &X[0, j], &inc) #tmp = X[:, j].dot(R)\n",
    "            beta[j] = soft_threshold_c2(tmp) * max(fabs(tmp) - alpha, 0) / norms_X_col[j] # l1 penalisation\n",
    "\n",
    "            if beta[j] != 0.:\n",
    "                mbetaj = - beta[j]\n",
    "                daxpy(&n, &mbetaj, &X[0, j], &inc, &beta_tmp[0], &inc) #R += - beta[j] * X[:, j]\n",
    "                \n",
    "    return beta\n",
    "\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "@cython.cdivision(True)\n",
    "def Cython_Lasso2(double[::1, :] X, double[:] y, float alpha, int max_iter=200):\n",
    "\n",
    "    cdef:\n",
    "        int n = X.shape[0]\n",
    "        int m = X.shape[1]\n",
    "        int inc = 1\n",
    "\n",
    "    cdef: #initialisation\n",
    "        double[:] sol\n",
    "        double[:] beta_tmp = np.empty(n, dtype=np.float64)\n",
    "        double[:] beta = np.zeros(m, dtype=np.float64)\n",
    "        double[:] norms_X_col = np.empty(m, dtype=np.float64)\n",
    "\n",
    "    for j in range(m):\n",
    "        norms_X_col[j] = ddot(&n, &X[0, j], &inc, &X[0, j], &inc)\n",
    "    with nogil:\n",
    "            \n",
    "        sol = fit2(X, norms_X_col, y, beta_tmp, beta, alpha, n, m, max_iter)\n",
    "\n",
    "    return np.asarray(sol)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "X_val = X.values.astype(np.float64)\n",
    "y_val = y.values.astype(np.float64)\n",
    "Cython_Lasso2(X_val, y_val, alpha=0.1, max_iter=500)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%timeit Cython_Lasso2(X_val, y_val, alpha=0.1, max_iter=500)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "memo_time.append(timeexe(\"Cython_Blas\", \"Cython_Lasso2(X_val, y_val, alpha=0.1, max_iter=500)\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2 id=\"4/-Parallel-features-optimization\">Parallel-features optimization<a class=\"anchor-link\" href=\"#4/-Parallel-features-optimization\">¶</a></h2><ul>\n",
    "<li><a href=\"https://stackoverflow.com/questions/59250916/can-this-problem-be-implemented-in-parallel-in-cython-with-openmp\">stackoverflow</a></li>\n",
    "<li><a href=\"https://github.com/IlyaTrofimov/dlr\">Original code</a></li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"4.1)-Version-homemade-parallélisée\"> homemade<a class=\"anchor-link\" href=\"#4.1)-Version-homemade-parallélisée\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%%cython\n",
    "cimport cython\n",
    "cimport numpy as cnp\n",
    "import numpy as np\n",
    "from cython.parallel import parallel, prange\n",
    "\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "@cython.cdivision(True)\n",
    "cdef double soft_threshold_c1(double rho, double alpha) nogil:\n",
    "    if rho < -alpha:\n",
    "        return (rho + alpha)\n",
    "    elif rho > alpha:\n",
    "        return (rho - alpha)\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "@cython.cdivision(True)\n",
    "cdef double[:] loss_c(double[:] y, double[:] y_pred, double[:] loss) nogil:\n",
    "        \n",
    "    for i in range(0, len(y)):\n",
    "        loss[i] += y[i] - y_pred[i]\n",
    "        \n",
    "    return loss\n",
    "\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "@cython.cdivision(True)\n",
    "cdef double[:] y_pred_c(double[:, :] X, double[:] tmp_beta, double[:] y_pred, int j) nogil:\n",
    "    \n",
    "    cdef:\n",
    "        int n = X.shape[0]\n",
    "        int m = X.shape[1]\n",
    "        \n",
    "    for i in range(0, n):\n",
    "        y_pred[i] += X[i, j] * tmp_beta[j]\n",
    "            \n",
    "    return y_pred\n",
    "\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "@cython.cdivision(True)\n",
    "cdef double rho_c(double[:, :] X, double[:] y_pred, double rho, int j) nogil:\n",
    "    \n",
    "    cdef int n = X.shape[0]\n",
    "        \n",
    "    for i in range(0, n):\n",
    "        rho += X[i, j] * y_pred[i]\n",
    "        \n",
    "    return rho\n",
    "\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "@cython.cdivision(True)\n",
    "cdef double normalisation_c(double[:, :] X, double X_nrm, int j) nogil:\n",
    "    \n",
    "    cdef int n = X.shape[0]\n",
    "        \n",
    "    for i in range(0, n):\n",
    "        X_nrm += X[i, j]**2\n",
    "        \n",
    "    return X_nrm\n",
    "\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "@cython.cdivision(True)\n",
    "cdef double[:] Parallel_fit1(double[:, :] X, double[:] y, int max_iter, float alpha,\n",
    "                             int n, int m, double[:] beta, double[:] tmp_beta,\n",
    "                             double[:] y_pred, double[:] loss, double X_nrm, double rho):\n",
    "\n",
    "    cdef int i, j\n",
    "\n",
    "    for i in range(max_iter):\n",
    "\n",
    "        for j in prange(m, nogil=True):\n",
    "            \n",
    "            y_pred_c(X, tmp_beta, y_pred, j)\n",
    "            loss_c(y, y_pred, loss)\n",
    "            rho_c(X, y_pred, rho, j)\n",
    "            beta[j] = soft_threshold_c1(rho, alpha) / normalisation_c(X, X_nrm, j) #(X.iloc[:, j]**2).sum()\n",
    "            \n",
    "    return beta\n",
    "\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "@cython.cdivision(True)\n",
    "def Parallel_Cython_Lasso1(double[:, :] X, double[:] y, float alpha, int max_iter):\n",
    "\n",
    "    cdef: #initialisation\n",
    "        int n = X.shape[0]\n",
    "        int m = X.shape[1]\n",
    "        double[:] beta = np.zeros(m, dtype=np.float64)\n",
    "        double[:] tmp_beta = np.zeros(m, dtype=np.float64)\n",
    "        double[:] y_pred = np.empty(n, dtype=np.float64)\n",
    "        double[:] loss = np.empty(n, dtype=np.float64)\n",
    "        double X_nrm = 0.0\n",
    "        double rho = 0.0\n",
    "        \n",
    "        sol = Parallel_fit1(X, y, max_iter, alpha, n, m, beta, tmp_beta, y_pred, loss, X_nrm, rho)\n",
    "\n",
    "    return np.asarray(sol)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_val = X.values.astype(np.float64)\n",
    "y_val = y.values.astype(np.float64)\n",
    "Parallel_Cython_Lasso1(X_val, y_val, alpha=0.1, max_iter=500)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%timeit Parallel_Cython_Lasso1(X_val, y_val, alpha=0.1, max_iter=500)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "memo_time.append(timeexe(\"Parallel_Cython_Homemade\", \"Parallel_Cython_Lasso1(X_val, y_val, alpha=0.1, max_iter=500)\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"4.2)-Version-Blas-parallélisée\">Blas<a class=\"anchor-link\" href=\"#4.2)-Version-Blas-parallélisée\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%%cython\n",
    "cimport cython\n",
    "cimport numpy as np\n",
    "import numpy as np\n",
    "from libc.math cimport fabs, sqrt\n",
    "from scipy.linalg.cython_blas cimport ddot, dasum, daxpy, dnrm2, dcopy, dscal\n",
    "from cython.parallel import parallel, prange\n",
    "\n",
    "\n",
    "cdef double soft_threshold_c2(double f) nogil:\n",
    "    if f == 0:\n",
    "        return 0\n",
    "    elif f > 0:\n",
    "        return 1.0\n",
    "    else:\n",
    "        return -1.0\n",
    "\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "@cython.cdivision(True)\n",
    "cdef double[:] Parallel_fit2(double[::1, :] X, double[:] norms_X_col, double[:] y,\n",
    "                            double[:] R, double[:] beta, double alpha,\n",
    "                            int n, int m, int max_iter):\n",
    "\n",
    "    cdef:\n",
    "        int inc = 1\n",
    "        int j\n",
    "        double tmp\n",
    "        double mbetaj\n",
    "\n",
    "    dcopy(&n, &y[0], &inc, &R[0], &inc) #R[0] <- y[0]\n",
    "    for i in range(max_iter):\n",
    "\n",
    "        for j in prange(m, nogil=True):\n",
    "\n",
    "            if beta[j] != 0.:\n",
    "                daxpy(&n, &beta[j], &X[0, j], &inc, &R[0], &inc) #R += X[:, j] * beta[j]\n",
    "                \n",
    "            tmp = ddot(&n, &R[0], &inc, &X[0, j], &inc) #tmp = X[:, j].dot(R)\n",
    "            beta[j] = soft_threshold_c2(tmp) * max(fabs(tmp) - alpha, 0) / norms_X_col[j] # l1 penalisation\n",
    "\n",
    "            if beta[j] != 0.:\n",
    "                mbetaj = - beta[j]\n",
    "                daxpy(&n, &mbetaj, &X[0, j], &inc, &R[0], &inc) #R += - beta[j] * X[:, j]\n",
    "                \n",
    "    return beta\n",
    "\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "@cython.cdivision(True)\n",
    "def Parallel_Cython_Lasso2(double[::1, :] X, double[:] y, float alpha, int max_iter):\n",
    "\n",
    "    cdef:\n",
    "        int n = X.shape[0]\n",
    "        int m = X.shape[1]\n",
    "        int inc = 1\n",
    "\n",
    "    cdef: #initialisation\n",
    "        double[:] sol\n",
    "        double[:] R = np.empty(n, dtype=np.float64)\n",
    "        double[:] beta = np.zeros(m, dtype=np.float64)\n",
    "        double[:] norms_X_col = np.empty(m, dtype=np.float64)\n",
    "    \n",
    "    for j in range(m):\n",
    "        norms_X_col[j] = ddot(&n, &X[0, j], &inc, &X[0, j], &inc)\n",
    "    \n",
    "    sol = Parallel_fit2(X, norms_X_col, y, R, beta, alpha, n, m, max_iter)\n",
    "\n",
    "    return np.asarray(sol)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "X_val = X.values.astype(np.float64)\n",
    "y_val = y.values.astype(np.float64)\n",
    "Parallel_Cython_Lasso2(X_val, y_val, alpha=0.1, max_iter=500)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%timeit Parallel_Cython_Lasso2(X_val, y_val, alpha=0.1, max_iter=500)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "memo_time.append(timeexe(\"Parallel_Cython_Blas\", \"Parallel_Cython_Lasso2(X_val, y_val, alpha=0.1, max_iter=500)\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2 id=\"5/-Algorithms-comparison\">Algorithms comparison<a class=\"anchor-link\" href=\"#5/-Algorithms-comparison\">¶</a></h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame(data=memo_time)\n",
    "df = df.set_index(\"legend\").sort_values(\"average\")\n",
    "cols = [\"average\", \"deviation\", \"min5\", \"max5\", \"run\", \"code\"]\n",
    "df[cols]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(14,6))\n",
    "df[[\"average\", \"deviation\"]].plot(kind=\"barh\", logx=True, ax=ax, xerr=\"deviation\",\n",
    "                                  legend=False, fontsize=12, width=0.8)\n",
    "ax.set_ylabel(\"\")\n",
    "ax.grid(b=True, which=\"major\")\n",
    "ax.grid(b=True, which=\"minor\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
